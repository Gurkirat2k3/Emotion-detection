{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0da161-0538-4556-a4a2-28b2b3db1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ed1c34-94fb-415e-9408-032c8d121ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cf8ab4-3c25-4be1-9bc8-08106ca165fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df50837e-deff-4f98-83fe-25e78650fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21a422b-f926-45d2-8b3b-00f602c6be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c6af2bb-e6ce-4f01-a5fe-cb585312314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da1593-dc72-4073-9c3f-ec2b462bee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edb32d-9d9b-4a62-bcd7-7a510da333dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33476855-9a83-43fb-aa55-92f715df55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale = True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58dc0a8-8f7f-4635-960c-2a8e717f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89ab1a-85df-4487-81fd-15b794ce1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8a690-704f-4388-8857-fdb12b60f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/22.50\n",
    "x_test = test_features/22.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fcb1c-49b4-4ccd-a7ac-345c0640c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663636ee-ecb5-4e51-a906-837836b782cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54455ad-13cf-4761-a42d-271321f46a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4103ece-47ba-4aaa-9c88-6eabc79c2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ee3e74-9644-438a-83a7-f453957e3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolution layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#output model\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412b8d50-8a8d-41d3-816b-c99804b06e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape = (40,48,1)))\n",
    "model.add(Dense(10, activation='softmax'))  # for 10 classes\n",
    "\n",
    "# Then compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54bad95-1763-438c-86c4-2d2b6989d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data (scale pixel values to 0–1)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fa91b2f-7ddc-44f0-a68e-37dcf5cf60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.8214 - loss: 0.6425 - val_accuracy: 0.9469 - val_loss: 0.1871\n",
      "Epoch 2/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9512 - loss: 0.1727 - val_accuracy: 0.9585 - val_loss: 0.1442\n",
      "Epoch 3/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9653 - loss: 0.1213 - val_accuracy: 0.9664 - val_loss: 0.1170\n",
      "Epoch 4/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9733 - loss: 0.0932 - val_accuracy: 0.9708 - val_loss: 0.0969\n",
      "Epoch 5/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9798 - loss: 0.0731 - val_accuracy: 0.9722 - val_loss: 0.0902\n",
      "Epoch 6/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0616 - val_accuracy: 0.9769 - val_loss: 0.0805\n",
      "Epoch 7/100\n",
      "\u001b[1m330/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0446"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_4372\\1619776124.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.fit(x=x_train, y=y_train, batch_size=\u001b[32m128\u001b[39m, epochs=\u001b[32m100\u001b[39m, validation_data=(x_test, y_test))\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    369\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m    371\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    374\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    375\u001b[39m \n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._async_train:\n\u001b[32m    170\u001b[39m             self._async_dispatch(self._on_train_batch_end, batch, logs)\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             self._on_train_batch_end(batch, logs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    192\u001b[39m         logs = python_utils.pythonify_logs(logs)\n\u001b[32m    193\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;28;01min\u001b[39;00m self.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m             callback.on_train_batch_end(batch, logs=logs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         self._update_progbar(batch, logs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\callbacks\\progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     91\u001b[39m         self._maybe_init_progbar()\n\u001b[32m     92\u001b[39m         self.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m             self.progbar.update(self.seen, list(logs.items()), finalize=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\progbar.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    159\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m self._values_order:\n\u001b[32m    160\u001b[39m                 info += f\" - {k}:\"\n\u001b[32m    161\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._values[k], list):\n\u001b[32m    162\u001b[39m                     avg = backend.convert_to_numpy(\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m                         backend.numpy.mean(\n\u001b[32m    164\u001b[39m                             self._values[k][\u001b[32m0\u001b[39m] / max(\u001b[32m1\u001b[39m, self._values[k][\u001b[32m1\u001b[39m])\n\u001b[32m    165\u001b[39m                         )\n\u001b[32m    166\u001b[39m                     )\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis, keepdims)\u001b[39m\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"int\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m ori_dtype \u001b[38;5;28;01mor\u001b[39;00m ori_dtype == \u001b[33m\"bool\"\u001b[39m:\n\u001b[32m    663\u001b[39m         result_dtype = compute_dtype\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    665\u001b[39m         result_dtype = ori_dtype\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     output = tf.reduce_mean(\n\u001b[32m    667\u001b[39m         tf.cast(x, compute_dtype), axis=axis, keepdims=keepdims\n\u001b[32m    668\u001b[39m     )\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(output, result_dtype)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m     89\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m     91\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2590\u001b[39m   keepdims = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(keepdims)\n\u001b[32m   2591\u001b[39m   return _may_reduce_to_scalar(\n\u001b[32m   2592\u001b[39m       keepdims, axis,\n\u001b[32m   2593\u001b[39m       gen_math_ops.mean(\n\u001b[32m-> \u001b[39m\u001b[32m2594\u001b[39m           input_tensor, _ReductionDims(input_tensor, axis), keepdims,\n\u001b[32m   2595\u001b[39m           name=name))\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis)\u001b[39m\n\u001b[32m   2094\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x_rank:\n\u001b[32m   2095\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op.constant(np.arange(x_rank, dtype=np.int32))\n\u001b[32m   2096\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2097\u001b[39m       \u001b[38;5;66;03m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2098\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m range(\u001b[32m0\u001b[39m, array_ops.rank(x))\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, dtype, name)\u001b[39m\n\u001b[32m   2065\u001b[39m     start = cast(start, inferred_dtype)\n\u001b[32m   2066\u001b[39m     limit = cast(limit, inferred_dtype)\n\u001b[32m   2067\u001b[39m     delta = cast(delta, inferred_dtype)\n\u001b[32m   2068\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m2069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops._range(start, limit, delta, name=name)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, name)\u001b[39m\n\u001b[32m   8020\u001b[39m         _ctx, \u001b[33m\"Range\"\u001b[39m, name, start, limit, delta)\n\u001b[32m   8021\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   8022\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   8023\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m8024\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   8025\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   8026\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   8027\u001b[39m       return _range_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f0ac1-8e00-46c8-ae48-1a2e0b4277fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d29f5c3c-c0c4-46c0-823e-ddb074a6367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98bfdc36-767d-4593-9665-baaecf8c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\",\"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04a7e140-6d01-4e4e-bec1-8aa0e91b5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry', 'disgust', 'fear', 'happy', 'netural', 'sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "325fdfb5-9f85-4c3c-b24c-4b51de24f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "    img = cv2.resize(img, (48, 48))                     # Resize to model's expected input\n",
    "    img = img / 255.0                                   # Normalize pixel values\n",
    "    img = np.reshape(img, (1, 48, 48, 1))               # Reshape for prediction\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a51ee6dc-9ac2-4412-aef9-5f12409d09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale = True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dab150a-8c81-44e0-aece-d5488fffebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal image is angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "model prediction is  happy\n",
      "angry: 0.0012\n",
      "disgust: 0.0000\n",
      "fear: 0.0003\n",
      "happy: 0.8578\n",
      "netural: 0.0185\n",
      "sad: 0.1220\n",
      "surprise: 0.0001\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/fear/2.jpg'\n",
    "print(\"orginal image is angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d048b6c9-3a48-4f86-aa45-508e4d71add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image counts per class:\n",
      "\n",
      "angry: 3993\n",
      "disgust: 436\n",
      "fear: 4103\n",
      "happy: 7164\n",
      "neutral: 4982\n",
      "sad: 4938\n",
      "surprise: 3205\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "data_dir = \"images/train\"\n",
    "classes = os.listdir(data_dir)\n",
    "class_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        count = len(os.listdir(cls_path))\n",
    "        class_counts[cls] = count\n",
    "\n",
    "print(\"Image counts per class:\\n\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41eb3df7-6eb9-4ba7-b621-ebc04382be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image_path):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.reshape(img, (1, 48, 48, 1))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e7a0f28-c38f-4fcd-b95d-a3e88ff86fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')  # 7 classes: angry, happy, etc.\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28599baf-7042-4abc-b75c-2cb404ff682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23060 images belonging to 7 classes.\n",
      "Found 5761 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images/train',\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    'images/train',\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1774db92-9d12-4484-9d8d-471ff39e8d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurkirat singh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 170ms/step - accuracy: 0.2377 - loss: 1.8282 - val_accuracy: 0.3723 - val_loss: 1.6267\n",
      "Epoch 2/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 78ms/step - accuracy: 0.3660 - loss: 1.6135 - val_accuracy: 0.4350 - val_loss: 1.4584\n",
      "Epoch 3/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.4354 - loss: 1.4592 - val_accuracy: 0.4702 - val_loss: 1.3746\n",
      "Epoch 4/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.4728 - loss: 1.3781 - val_accuracy: 0.4850 - val_loss: 1.3239\n",
      "Epoch 5/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - accuracy: 0.5036 - loss: 1.3058 - val_accuracy: 0.5027 - val_loss: 1.2850\n",
      "Epoch 6/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5239 - loss: 1.2516 - val_accuracy: 0.5207 - val_loss: 1.2562\n",
      "Epoch 7/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 87ms/step - accuracy: 0.5414 - loss: 1.2084 - val_accuracy: 0.5216 - val_loss: 1.2557\n",
      "Epoch 8/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.5586 - loss: 1.1725 - val_accuracy: 0.5376 - val_loss: 1.2396\n",
      "Epoch 9/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.5699 - loss: 1.1344 - val_accuracy: 0.5384 - val_loss: 1.2273\n",
      "Epoch 10/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 99ms/step - accuracy: 0.5842 - loss: 1.1008 - val_accuracy: 0.5437 - val_loss: 1.2195\n",
      "Epoch 11/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.5916 - loss: 1.0650 - val_accuracy: 0.5327 - val_loss: 1.2337\n",
      "Epoch 12/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.6078 - loss: 1.0374 - val_accuracy: 0.5475 - val_loss: 1.2241\n",
      "Epoch 13/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.6192 - loss: 1.0046 - val_accuracy: 0.5515 - val_loss: 1.2295\n",
      "Epoch 14/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.6353 - loss: 0.9694 - val_accuracy: 0.5511 - val_loss: 1.2211\n",
      "Epoch 15/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 92ms/step - accuracy: 0.6398 - loss: 0.9455 - val_accuracy: 0.5499 - val_loss: 1.2545\n",
      "Epoch 16/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.6512 - loss: 0.9191 - val_accuracy: 0.5525 - val_loss: 1.2644\n",
      "Epoch 17/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - accuracy: 0.6626 - loss: 0.8898 - val_accuracy: 0.5563 - val_loss: 1.3091\n",
      "Epoch 18/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 99ms/step - accuracy: 0.6760 - loss: 0.8547 - val_accuracy: 0.5542 - val_loss: 1.2963\n",
      "Epoch 19/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - accuracy: 0.6857 - loss: 0.8240 - val_accuracy: 0.5503 - val_loss: 1.2863\n",
      "Epoch 20/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.6970 - loss: 0.7942 - val_accuracy: 0.5480 - val_loss: 1.3128\n",
      "Epoch 21/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7020 - loss: 0.7834 - val_accuracy: 0.5529 - val_loss: 1.3768\n",
      "Epoch 22/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7114 - loss: 0.7518 - val_accuracy: 0.5459 - val_loss: 1.3886\n",
      "Epoch 23/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7195 - loss: 0.7331 - val_accuracy: 0.5492 - val_loss: 1.3889\n",
      "Epoch 24/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7313 - loss: 0.6931 - val_accuracy: 0.5558 - val_loss: 1.4985\n",
      "Epoch 25/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7367 - loss: 0.6776 - val_accuracy: 0.5485 - val_loss: 1.5040\n",
      "Epoch 26/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7373 - loss: 0.6754 - val_accuracy: 0.5529 - val_loss: 1.4914\n",
      "Epoch 27/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7495 - loss: 0.6442 - val_accuracy: 0.5508 - val_loss: 1.5800\n",
      "Epoch 28/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7484 - loss: 0.6316 - val_accuracy: 0.5445 - val_loss: 1.6120\n",
      "Epoch 29/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 90ms/step - accuracy: 0.7592 - loss: 0.6110 - val_accuracy: 0.5476 - val_loss: 1.6415\n",
      "Epoch 30/30\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.7644 - loss: 0.5998 - val_accuracy: 0.5501 - val_loss: 1.6273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27005ed45f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "098f1a54-7b84-4f12-af89-e116045e5046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save model architecture to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save weights (✅ fixed filename)\n",
    "model.save_weights(\"emotion_model.weights.h5\")\n",
    "\n",
    "print(\"✅ Model saved to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "747af425-31a5-4d56-a96d-199a7e078472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"emotion_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c1bc8ca-ea38-4288-a54a-4155805a3b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"emotion_model.h5\")\n",
    "print(\"✅ Full model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06530348-3562-450c-bb31-43727f775f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.2288 - loss: 1.9305\n",
      "Test Loss: 1.9352, Test Accuracy: 0.2525\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'images/test',            # path to your test folder\n",
    "    target_size=(48, 48),     # same size as training images\n",
    "    color_mode='grayscale',   # if your model expects grayscale images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False             # keep False for evaluation\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2431ea62-208d-41f5-baeb-f761ebf88b43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss, accuracy = model.evaluate(\u001b[43mtest_generator\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf769ff-0e7e-492f-ac72-899a3a3bd8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
